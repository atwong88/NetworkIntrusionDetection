{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "A minimalistic Echo State Networks demo with Mackey-Glass (delay 17) data \n",
    "in \"plain\" scientific Python.\n",
    "by Mantas LukoÅ¡eviÄius 2012-2018\n",
    "http://mantas.info\n",
    "\"\"\"\n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *\n",
    "import scipy.linalg\n",
    "\n",
    "# load the data\n",
    "trainLen = 2000\n",
    "testLen = 2000\n",
    "initLen = 100\n",
    "data = loadtxt('MackeyGlass_t17.txt')\n",
    "\n",
    "# plot some of it\n",
    "figure(10).clear()\n",
    "plot(data[0:1000])\n",
    "title('A sample of data')\n",
    "\n",
    "# generate the ESN reservoir\n",
    "inSize = outSize = 1\n",
    "resSize = 100\n",
    "a = 0.3 # leaking rate\n",
    "random.seed(42)\n",
    "Win = (random.rand(resSize,1+inSize)-0.5) * 1\n",
    "W = random.rand(resSize,resSize)-0.5 \n",
    "# normalizing and setting spectral radius (correct, slow):\n",
    "print('Computing spectral radius...'),\n",
    "rhoW = max(abs(linalg.eig(W)[0]))\n",
    "print('done.')\n",
    "W *= 1.25 / rhoW\n",
    "\n",
    "# allocated memory for the design (collected states) matrix\n",
    "X = zeros((1+inSize+resSize,trainLen-initLen))\n",
    "# set the corresponding target matrix directly\n",
    "Yt = data[None,initLen+1:trainLen+1] \n",
    "\n",
    "# run the reservoir with the data and collect X\n",
    "x = zeros((resSize,1))\n",
    "for t in range(trainLen):\n",
    "    u = data[t]\n",
    "    x = (1-a)*x + a*tanh( dot( Win, vstack((1,u)) ) + dot( W, x ) )\n",
    "    if t >= initLen:\n",
    "        X[:,t-initLen] = vstack((1,u,x))[:,0]\n",
    "    \n",
    "# train the output by ridge regression\n",
    "reg = 1e-8  # regularization coefficient\n",
    "X_T = X.T\n",
    "Wout = dot( dot(Yt,X_T), linalg.inv( dot(X,X_T) + \\\n",
    "    reg*eye(1+inSize+resSize) ) )\n",
    "\n",
    "# run the trained ESN in a generative mode. no need to initialize here, \n",
    "# because x is initialized with training data and we continue from there.\n",
    "Y = zeros((outSize,testLen))\n",
    "u = data[trainLen]\n",
    "for t in range(testLen):\n",
    "    x = (1-a)*x + a*tanh( dot( Win, vstack((1,u)) ) + dot( W, x ) )\n",
    "    y = dot( Wout, vstack((1,u,x)) )\n",
    "    Y[:,t] = y\n",
    "    # generative mode:\n",
    "    u = y\n",
    "    ## this would be a predictive mode:\n",
    "    #u = data[trainLen+t+1] \n",
    "\n",
    "# compute MSE for the first errorLen time steps\n",
    "errorLen = 500\n",
    "mse = sum( square( data[trainLen+1:trainLen+errorLen+1] - \n",
    "    Y[0,0:errorLen] ) ) / errorLen\n",
    "print('MSE = ' + str( mse ))\n",
    "    \n",
    "# plot some signals\n",
    "figure(1).clear()\n",
    "plot( data[trainLen+1:trainLen+testLen+1], 'g' )\n",
    "plot( Y.T, 'b' )\n",
    "title('Target and generated signals $y(n)$ starting at $n=0$')\n",
    "legend(['Target signal', 'Free-running predicted signal'])\n",
    "\n",
    "figure(2).clear()\n",
    "plot( X[0:20,0:200].T )\n",
    "title('Some reservoir activations $\\mathbf{x}(n)$')\n",
    "\n",
    "figure(3).clear()\n",
    "bar( range(1+inSize+resSize), Wout.T )\n",
    "title('Output weights $\\mathbf{W}^{out}$')\n",
    "\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
